{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNChaUUdYVPbagqGaiQpLeF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xvjNPxVAA18u","executionInfo":{"status":"ok","timestamp":1717622268991,"user_tz":180,"elapsed":386,"user":{"displayName":"ian bezerra","userId":"05417333999231090698"}},"outputId":"d6386eb4-cdeb-41c0-f82b-6664ed4ac6b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Weights: tensor([2.4314])\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","# Generate some dummy data\n","torch.manual_seed(0)\n","X = torch.rand(100, 1) * 10  # Features\n","y = 2.5 * X + 3 + torch.randn(100, 1)  # Labels with some noise\n","\n","# Assuming a linear model y = wX + b, we can rewrite this as y = Ap, where A = [X 1] and p = [w, b]\n","A = torch.cat((X, torch.ones(100, 1)), dim=1)\n","\n","# Using the normal equation to solve for p: (A^T A) p = A^T y\n","# We can use LU decomposition to solve this\n","AtA = torch.mm(A.T, A)\n","Aty = torch.mm(A.T, y)\n","\n","# LU decomposition of AtA\n","LU, pivots = torch.lu(AtA)\n","\n","# Solving the equation using the LU factors\n","p, _ = torch.lu_solve(Aty, LU, pivots)\n","\n","# Print the computed weights\n","print(f\"Weights: {p.flatten()}\")  # Should be close to [2.5, 3]\n"]},{"cell_type":"code","source":["import numpy as np\n","\n","class Neuron():\n","    def __init__(self, x):\n","        self.weights = np.random.randn(2)\n","\n","    def forward(self, x):\n","        act = np.tanh(np.dot(x, self.weights))\n","        return act\n","\n","class Layer():\n","    def __init__(self, n_in, n_out):\n","        self.neurons = [Neuron(n_in) for _ in range(n_out)]\n","\n","    def forward(self, x):\n","        return sum([n.forward(x) for n in self.neurons])\n","\"\"\"\n","Resultados Desejados!\n","x = [2, 2]\n","o = [10]\n","\"\"\"\n","\n","\n","#n = Neuron([2, 3])\n","L = Layer(2, 2)\n","print(L.forward([1, 2]))\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VXi-PRzrmh8G","executionInfo":{"status":"ok","timestamp":1717961587140,"user_tz":180,"elapsed":5,"user":{"displayName":"ian bezerra","userId":"05417333999231090698"}},"outputId":"00f1722b-fad5-463e-9f38-b321abfaf936"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["-0.12284090828149452\n"]}]},{"cell_type":"code","source":["class Neuron():\n","    def __init__(self, weights=None):\n","        if weights is None:\n","            self.weights = np.random.randn(2)\n","        else:\n","            self.weights = np.array(weights)\n","\n","    def forward(self, x):\n","        act =(np.dot(x, self.weights))\n","        return act\n","\n","class Layer():\n","    def __init__(self, n_in, n_out):\n","        self.neurons = [Neuron() for _ in range(n_out)]\n","\n","    def forward(self, x):\n","        return np.array([neuron.forward(x) for neuron in self.neurons])\n","\n","# Function to solve for weights\n","def solve_weights(x, o, n_neurons):\n","    x = np.array(x)\n","    o = np.array(o)\n","    A = np.tile(x, (n_neurons, 1))\n","    b = o\n","\n","    # Solve for weights\n","    weights = np.linalg.lstsq(A.T, b, rcond=None)[0]\n","\n","    return weights\n","\n","# Example usage\n","x = [2, 2]\n","o = [20, 20]\n","n_neurons = 2\n","\n","weights = solve_weights(x, o, n_neurons)\n","print(\"Weights:\", weights)\n","\n","# Set weights to the layer\n","L = Layer(2, 2)\n","for i, neuron in enumerate(L.neurons):\n","    neuron.weights = weights\n","\n","print(L.forward([2, 2]))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pJvytag4pV8w","executionInfo":{"status":"ok","timestamp":1717633834194,"user_tz":180,"elapsed":525,"user":{"displayName":"ian bezerra","userId":"05417333999231090698"}},"outputId":"759cf985-f1f0-4e3b-a0c1-41051ba9ebb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Weights: [5. 5.]\n","[20. 20.]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","class Neuron():\n","    def __init__(self, weights=None):\n","        if weights is None:\n","            self.weights = np.random.randn(2)\n","        else:\n","            self.weights = np.array(weights)\n","\n","    def forward(self, x):\n","        act = np.dot(x, self.weights)\n","        return act\n","\n","class Layer():\n","    def __init__(self, n_in, n_out):\n","        self.neurons = [Neuron() for _ in range(n_out)]\n","\n","    def forward(self, x):\n","        return sum([neuron.forward(x) for neuron in self.neurons])\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# Function to solve for weights\n","def solve_weights(x, o, n_neurons):\n","    x = np.array(x)\n","    A = np.tile(x, (n_neurons, 1))\n","    b = np.array([o/n_neurons] * n_neurons)  # Desired output repeated for each neuron\n","\n","    # Solve for weights\n","    weights, residuals, rank, s = np.linalg.lstsq(A, b, rcond=None)\n","\n","    return weights\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# Example usage\n","x = [10, 10]\n","o = 20  # Desired single output\n","n_neurons = 2\n","\n","weights = solve_weights(x, o, n_neurons)\n","print(\"Weights:\", weights)\n","\n","# Set weights to the layer\n","L = Layer(2, 2)\n","print(L.forward(x))\n","for i, neuron in enumerate(L.neurons):\n","    neuron.weights = weights\n","\n","output = L.forward(x)\n","print(\"Output:\", output)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Az_nMv6q9Lyh","executionInfo":{"status":"ok","timestamp":1717961916364,"user_tz":180,"elapsed":4,"user":{"displayName":"ian bezerra","userId":"05417333999231090698"}},"outputId":"f482bd3c-cec9-417f-dfe3-5ff3d1c1d4c3"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Weights: [0.5 0.5]\n","-12.973602763650323\n","Output: 19.999999999999996\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","class Neuron():\n","    def __init__(self, weights=None):\n","        if weights is None:\n","            self.weights = np.random.randn(2)\n","        else:\n","            self.weights = np.array(weights)\n","\n","    def forward(self, x):\n","        act = np.dot(x, self.weights)\n","        return act\n","\n","class Layer():\n","    def __init__(self, n_in, n_out):\n","        self.neurons = [Neuron() for _ in range(n_out)]\n","\n","    def forward(self, x):\n","        return sum([neuron.forward(x) for neuron in self.neurons])\n","\n","#-----------------------------------------------------------------------------\n","\n","\n","def solve_weights_cholesky(x, o, n_neurons):\n","    x = np.array(x)\n","    A = np.tile(x, (n_neurons, 1))\n","    b = np.array([o/n_neurons] * n_neurons)\n","\n","    AtA = np.dot(A.T, A)\n","    Atb = np.dot(A.T, b)\n","\n","    # Cholesky\n","    L = np.linalg.cholesky(AtA)\n","\n","    # L y = A^T b for y\n","    y = np.linalg.solve(L, Atb)\n","\n","    # L^T x = y for x (pesos)\n","    weights = np.linalg.solve(L.T, y)\n","\n","    return weights\n","\n","# Exemplo...\n","x = [2, 2]\n","o = 20\n","n_neurons = 2\n","\n","L = Layer(2, 2)\n","print(f\"Output não Treinado: {L.forward([2,2])}\")\n","\n","\n","\n","weights = solve_weights_cholesky(x, o, n_neurons)\n","print(\"Weights:\", weights)\n","\n","for i, neuron in enumerate(L.neurons):\n","    neuron.weights = weights\n","\n","output = L.forward([2,2])\n","print(\"Output:\", output)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nh0xUMms99m1","executionInfo":{"status":"ok","timestamp":1717962276203,"user_tz":180,"elapsed":366,"user":{"displayName":"ian bezerra","userId":"05417333999231090698"}},"outputId":"35a5970a-e7aa-4f31-d805-c75f942c5ec3"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Output não Treinado: -0.9109831646651954\n","Weights: [1. 4.]\n","Output: 20.0\n"]}]}]}