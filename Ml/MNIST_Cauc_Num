{"cells":[{"cell_type":"markdown","source":["# MNIST Database MLP optimization with Numerical Methods!"],"metadata":{"id":"r-QHhKKsgeLe"}},{"cell_type":"markdown","source":["## Getting the data from the Built in MNIST Data set in tensorflow Module"],"metadata":{"id":"8CDzH2jLgueI"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","\n","def load_and_preprocess_mnist():\n","    # Load the MNIST dataset\n","    (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n","\n","    # Normalize and flatten the images\n","    # Normalizing the pixel values to 0 or 1 based on a threshold, similar to your Pygame app\n","    threshold = 128\n","    train_images_flattened = np.where(train_images > threshold, 1, 0).reshape(train_images.shape[0], -1)\n","    test_images_flattened = np.where(test_images > threshold, 1, 0).reshape(test_images.shape[0], -1)\n","\n","    return (train_images_flattened, train_labels), (test_images_flattened, test_labels)\n","\n","# Usage\n","(train_images_flattened, train_labels), (test_images_flattened, test_labels) = load_and_preprocess_mnist()\n","\n","\n"],"metadata":{"id":"FUqllZsIgs7h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Example: Print the first flattened image and its label\n","#print(\"First training image (flattened):\", train_images_flattened[200])\n","#n = int(input(\"Enter a number of the index up to 60k: \"))\n","#print(\"Label of the first training image:\", train_labels[n])\n","print(\"----------------------------------------\")\n","#print(f\"The data set is {len(train_images_flattened)} long:\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"194QtatkhC4Q","executionInfo":{"status":"ok","timestamp":1717013249056,"user_tz":180,"elapsed":14,"user":{"displayName":"ian bezerra","userId":"05417333999231090698"}},"outputId":"27a6e34e-0fa6-4c91-c4ef-7059c6c16e61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------\n"]}]},{"cell_type":"markdown","source":["# ---------------------------------------------------------------------"],"metadata":{"id":"4iI3y_ijg3x_"}},{"cell_type":"markdown","source":["## Making a Pygame Grid That Reconstruct the Image!"],"metadata":{"id":"58WYTuFQhSIv"}},{"cell_type":"code","source":["\"\"\"\n","---------------------------------------------------------------------------------\n","\n","// Reconstructing //\n","\n","\n","\"\"\"\n","import pygame\n","import sys\n","import re\n","\n","CELL_SIZE = 35\n","GRID_SIZE = 28\n","WIDTH = HEIGHT = GRID_SIZE * CELL_SIZE\n","WHITE = (255, 255, 255)\n","BLACK = (0, 0, 0)\n","\n","def reconstruct(flattened_array):\n","    pygame.init()\n","    screen = pygame.display.set_mode((WIDTH, HEIGHT))\n","    pygame.display.set_caption(\"28x28 Grid Reconstruction from Input\")\n","\n","    flattened_array\n","\n","    grid = [flattened_array[i * GRID_SIZE:(i + 1) * GRID_SIZE] for i in range(GRID_SIZE)]\n","\n","    running = True\n","    while running:\n","        for event in pygame.event.get():\n","            if event.type == pygame.QUIT:\n","                running = False\n","\n","        for row in range(GRID_SIZE):\n","            for col in range(GRID_SIZE):\n","                color = BLACK if grid[row][col] == 1 else WHITE\n","                pygame.draw.rect(screen, color, pygame.Rect(col * CELL_SIZE, row * CELL_SIZE, CELL_SIZE, CELL_SIZE))\n","\n","        pygame.display.flip()\n","\n","    pygame.quit()\n","    sys.exit()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cB2XzkK6hRjQ","executionInfo":{"status":"ok","timestamp":1717013249056,"user_tz":180,"elapsed":12,"user":{"displayName":"ian bezerra","userId":"05417333999231090698"}},"outputId":"48e85491-b659-4b8f-8e50-a932eb7a4817"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n","Hello from the pygame community. https://www.pygame.org/contribute.html\n"]}]},{"cell_type":"code","source":["\n","\"\"\"\n","---------------------------------------------------------------------------------\n","\n","// Calling the Function //\n","\n","\n","\"\"\"\n","\n","\n","\n","\n","#reconstruct(train_images_flattened[n])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"1sQqw5TPhouu","executionInfo":{"status":"ok","timestamp":1717013249056,"user_tz":180,"elapsed":10,"user":{"displayName":"ian bezerra","userId":"05417333999231090698"}},"outputId":"6468ec73-7fdc-4883-e1c1-b6dad092e5d6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n---------------------------------------------------------------------------------\\n\\n// Calling the Function //\\n\\n\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["# ---------------------------------------------------------------------"],"metadata":{"id":"ypAbCGHYhhzY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PQy4d25KHfbU"},"outputs":[],"source":["import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["\n","class Neuron(torch.nn.Module):\n","    def __init__(self, nin):\n","        super(Neuron, self).__init__()\n","        self.w = torch.nn.Parameter(torch.randn(nin, dtype=torch.double))\n","        self.b = torch.nn.Parameter(torch.randn(1, dtype=torch.double))\n","\n","    def forward(self, x):\n","        if isinstance(x, list):\n","            x = torch.tensor(x, dtype=torch.double)\n","        act = torch.dot(self.w, x) + self.b\n","        return torch.tanh(act)\n","\n"],"metadata":{"id":"t7K8-eOZeMVq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Layer(torch.nn.Module):\n","    def __init__(self, nin, nout):\n","        super(Layer, self).__init__()\n","        self.neurons = torch.nn.ModuleList([Neuron(nin) for _ in range(nout)])\n","\n","    def forward(self, x):\n","        outs = [neuron(x) for neuron in self.neurons]\n","        return outs[0] if len(outs) == 1 else torch.cat(outs, dim=0)\n","\n"],"metadata":{"id":"zaUhdslufLsM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MLP(torch.nn.Module):\n","    def __init__(self, nin, nouts):\n","        super(MLP, self).__init__()\n","        sz = [nin] + nouts\n","        self.layers = torch.nn.ModuleList([Layer(sz[i], sz[i+1]) for i in range(len(nouts))])\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","\n","        return x\n"],"metadata":{"id":"26qe4z72GWm1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sample data\n","# xs = [[0.5, -1.5], [1.0, 1.0], [-0.5, -0.5]]\n","# ys = [1.0, -1.0, 0.5]\n","#xs = train_images_flattened[n]\n","#image_tensor = torch.tensor(train_images_flattened[n], dtype=torch.double, device=device)\n","\n","# Create MLP\n","nin = 784\n","nouts = [256, 128, 10]\n","#n = MLP(nin, nouts)\n","\n","brein = MLP(nin, nouts).to(device)  # Move model to device\n","# Convert input data to tensors and move to the device\n","#xs = [torch.tensor(x, dtype=torch.double, device=device) for x in xs]\n","#ys = torch.tensor(ys, dtype=torch.double, device=device)\n","\n","# Now proceed with training using the adjusted model and tensors\n"],"metadata":{"id":"l2H4YWPbXKcC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#brein(image_tensor)"],"metadata":{"id":"sCTDAQ-Pjd0C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training loop\n","for k in range(1):\n","    # Forward pass\n","    in_data = train_images_flattened[0:10]\n","    in_labels = train_labels[0:10]\n","    #print(len(train_images_flattened))\n","    xs =  [torch.tensor(data, dtype=torch.double, device=device) for data in in_data]\n","    ypred = [brein(im) for im in xs]\n","    ys = []\n","    for npred in in_labels:\n","      item_pred = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.double, device=device)\n","      item_pred[npred] = 1\n","      ys.append(item_pred)\n","\n","    #loss = 0\n","    loss = torch.tensor(0, dtype=torch.double, device=device)\n","    for val, pred in zip(ys, ypred):\n","      loss += sum((yout - ygt)**2 for ygt, yout in zip(val, pred))\n","\n","    #loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n","    #print(loss)\n","\n","\n","    # Backward pass\n","    for p in brein.parameters():\n","        if p.grad is not None:\n","            p.grad.zero_()\n","    loss.backward()\n","\n","    # Update\n","    with torch.no_grad():\n","        for p in brein.parameters():\n","            if p.grad is not None:\n","                p -= 1 * p.grad\n","\n","    print(k, loss.item())\n","\n","k = 0\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uXkYW2mxVKU5","executionInfo":{"status":"ok","timestamp":1717013251930,"user_tz":180,"elapsed":649,"user":{"displayName":"ian bezerra","userId":"05417333999231090698"}},"outputId":"350f3fea-3f23-4c12-c6d2-c5d12a0695fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 94.88701810933563\n"]}]},{"cell_type":"code","source":["\n","\"\"\"\n","optimizer = torch.optim.SGD(brein.parameters(), lr=0.001)  # Define optimizer\n","\n","loss_threshold = 10\n","k = 0  # Ensure 'k' is initialized properly outside the loop if needed\n","while True:\n","    loss = torch.tensor(0.0, dtype=torch.double, device=device)  # Initialize loss\n","    for i in range(1000):\n","        # Forward pass: Assuming train_images_flattened and train_labels are properly defined\n","        in_data = train_images_flattened[k:k+10]\n","        in_labels = train_labels[k:k+10]\n","        xs = [torch.tensor(data, dtype=torch.double, device=device) for data in in_data]\n","        ypred = [brein(im) for im in xs]\n","        ys = []\n","        for npred in in_labels:\n","            item_pred = torch.zeros(10, dtype=torch.double, device=device)\n","            item_pred[npred] = 1\n","            ys.append(item_pred)\n","\n","        # Compute loss\n","        loss = torch.tensor(0.0, dtype=torch.double, device=device)  # Reset loss for each batch\n","        for val, pred in zip(ys, ypred):\n","            loss += torch.sum((pred - val) ** 2)\n","\n","        # Backward pass\n","        optimizer.zero_grad()  # Clear existing gradients\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Update parameters\n","\n","        print(k, loss.item())\n","\n","        if loss.item() < loss_threshold:\n","            break\n","\n","    k += 10  # Increment by the batch size\n","    if loss.item() < loss_threshold:\n","        break\n","  \"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"id":"o6irWttn12WW","executionInfo":{"status":"ok","timestamp":1717013251930,"user_tz":180,"elapsed":8,"user":{"displayName":"ian bezerra","userId":"05417333999231090698"}},"outputId":"cd5b1f27-705b-4059-f672-d3eb6a21befd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\noptimizer = torch.optim.SGD(brein.parameters(), lr=0.001)  # Define optimizer\\n\\nloss_threshold = 10\\nk = 0  # Ensure 'k' is initialized properly outside the loop if needed\\nwhile True:\\n    loss = torch.tensor(0.0, dtype=torch.double, device=device)  # Initialize loss\\n    for i in range(1000):\\n        # Forward pass: Assuming train_images_flattened and train_labels are properly defined\\n        in_data = train_images_flattened[k:k+10]\\n        in_labels = train_labels[k:k+10]\\n        xs = [torch.tensor(data, dtype=torch.double, device=device) for data in in_data]\\n        ypred = [brein(im) for im in xs]\\n        ys = []\\n        for npred in in_labels:\\n            item_pred = torch.zeros(10, dtype=torch.double, device=device)\\n            item_pred[npred] = 1\\n            ys.append(item_pred)\\n\\n        # Compute loss\\n        loss = torch.tensor(0.0, dtype=torch.double, device=device)  # Reset loss for each batch\\n        for val, pred in zip(ys, ypred):\\n            loss += torch.sum((pred - val) ** 2)\\n\\n        # Backward pass\\n        optimizer.zero_grad()  # Clear existing gradients\\n        loss.backward()  # Compute gradients\\n        optimizer.step()  # Update parameters\\n\\n        print(k, loss.item())\\n\\n        if loss.item() < loss_threshold:\\n            break\\n\\n    k += 10  # Increment by the batch size\\n    if loss.item() < loss_threshold:\\n        break\\n  \""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["optimizer = torch.optim.SGD(brein.parameters(), lr=10)  # Define optimizer\n","\n","loss_threshold = 10\n","batch_size = 3\n","k = 0  # Ensure 'k' is initialized properly outside the loop if needed\n","while True:\n","    loss = torch.tensor(0.0, dtype=torch.double, device=device)  # Initialize loss\n","    in_data = train_images_flattened[k:k+batch_size]\n","    in_labels = train_labels[k:k+batch_size]\n","    xs = [torch.tensor(data, dtype=torch.double, device=device) for data in in_data]\n","\n","    ys = []\n","    for npred in in_labels:\n","        item_pred = torch.zeros(10, dtype=torch.double, device=device)\n","        item_pred[npred] = 1\n","        ys.append(item_pred)\n","\n","\n","    for i in range(1000):\n","        # Forward pass: Assuming train_images_flattened and train_labels are properly defined\n","        ypred = [brein(im) for im in xs]\n","\n","\n","        # Compute loss\n","        loss = torch.tensor(0.0, dtype=torch.double, device=device)  # Reset loss for each batch\n","        for val, pred in zip(ys, ypred):\n","            loss += torch.sum((pred - val) ** 2)\n","\n","        # Backward pass\n","        optimizer.zero_grad()  # Clear existing gradients\n","        loss.backward()  # Compute gradients\n","        optimizer.step()  # Update parameters\n","\n","        print(k, loss.item())\n","\n","        if loss.item() < loss_threshold:\n","            break\n","\n","    k += batch_size  # Increment by the batch size\n","    if loss.item() < loss_threshold:\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FJL2vq4W9i7_","outputId":"c93dbdc4-b0f6-4077-a065-105476b371e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 26.999997283588463\n","0 26.999997245392258\n","0 26.999997206107004\n","0 26.999997165685574\n","0 26.999997124078067\n","0 26.999997081231648\n","0 26.999997037090274\n","0 26.999996991594493\n","0 26.99999694468117\n","0 26.99999689628317\n","0 26.999996846329076\n","0 26.99999679474283\n","0 26.99999674144334\n","0 26.999996686344055\n","0 26.999996629352513\n","0 26.999996570369824\n","0 26.999996509290103\n","0 26.999996445999834\n","0 26.999996380377183\n","0 26.999996312291216\n","0 26.99999624160102\n","0 26.999996168154787\n","0 26.99999609178867\n","0 26.999996012325624\n","0 26.999995929574045\n","0 26.99999584332621\n","0 26.999995753356583\n","0 26.999995659419866\n","0 26.999995561248785\n","0 26.99999545855156\n","0 26.99999535100908\n","0 26.999995238271588\n","0 26.99999511995496\n","0 26.999994995636364\n","0 26.99999486484927\n","0 26.999994727077706\n","0 26.999994581749498\n","0 26.999994428228476\n","0 26.999994265805245\n","0 26.999994093686432\n","0 26.99999391098187\n","0 26.999993716689453\n","0 26.99999350967701\n","0 26.999993288660587\n","0 26.99999305217824\n","0 26.99999279855816\n","0 26.99999252587983\n","0 26.999992231926125\n","0 26.999991914124063\n","0 26.999991569470712\n","0 26.999991194439954\n","0 26.999990784863883\n","0 26.999990335780673\n","0 26.999989841237134\n","0 26.999989294029625\n","0 26.99998868535959\n","0 26.99998800436937\n","0 26.99998723750676\n","0 26.999986367640393\n","0 26.999985372804623\n","0 26.999984224380572\n","0 26.99998288439601\n","0 26.999981301406624\n","0 26.999979404013622\n","0 26.999977090284197\n","0 26.999974209734532\n","0 26.999970531050533\n","0 26.999965680593693\n","0 26.999959015999657\n","0 26.999949340003695\n","0 26.999934164591235\n","0 26.99990745432852\n","0 26.999850625465594\n","0 26.999676480156214\n","0 26.998275290224527\n","0 26.281980131964257\n","0 26.9999999684905\n","0 26.999999968463882\n","0 26.99999996843721\n","0 26.999999968410478\n","0 26.99999996838369\n","0 26.99999996835685\n","0 26.999999968329952\n","0 26.999999968302994\n","0 26.99999996827598\n","0 26.999999968248908\n","0 26.999999968221783\n","0 26.9999999681946\n","0 26.99999996816736\n","0 26.99999996814006\n","0 26.999999968112697\n","0 26.999999968085284\n","0 26.999999968057807\n","0 26.999999968030274\n","0 26.999999968002683\n","0 26.99999996797503\n","0 26.999999967947318\n","0 26.999999967919546\n","0 26.999999967891714\n","0 26.99999996786383\n","0 26.999999967835876\n","0 26.99999996780786\n","0 26.999999967779793\n","0 26.999999967751656\n","0 26.99999996772347\n","0 26.99999996769521\n","0 26.99999996766689\n","0 26.99999996763851\n","0 26.999999967610066\n","0 26.99999996758157\n","0 26.999999967553002\n","0 26.999999967524374\n","0 26.999999967495683\n","0 26.999999967466927\n","0 26.99999996743811\n","0 26.999999967409227\n","0 26.999999967380283\n","0 26.999999967351275\n","0 26.9999999673222\n","0 26.999999967293064\n","0 26.99999996726386\n","0 26.999999967234594\n","0 26.999999967205262\n","0 26.99999996717586\n","0 26.999999967146394\n","0 26.999999967116864\n","0 26.99999996708727\n","0 26.999999967057605\n","0 26.999999967027875\n","0 26.999999966998075\n","0 26.99999996696821\n","0 26.99999996693828\n","0 26.99999996690828\n","0 26.999999966878214\n","0 26.999999966848076\n","0 26.999999966817875\n","0 26.9999999667876\n","0 26.999999966757255\n","0 26.999999966726847\n","0 26.999999966696365\n","0 26.99999996666581\n","0 26.999999966635187\n","0 26.9999999666045\n","0 26.999999966573736\n","0 26.9999999665429\n","0 26.999999966512\n","0 26.99999996648102\n","0 26.999999966449977\n","0 26.999999966418855\n","0 26.99999996638766\n","0 26.9999999663564\n","0 26.999999966325056\n","0 26.99999996629365\n","0 26.999999966262166\n","0 26.999999966230607\n","0 26.999999966198978\n","0 26.999999966167266\n","0 26.999999966135483\n","0 26.99999996610363\n","0 26.999999966071698\n","0 26.99999996603969\n","0 26.999999966007614\n","0 26.999999965975455\n","0 26.999999965943218\n","0 26.999999965910902\n","0 26.99999996587852\n","0 26.99999996584605\n","0 26.999999965813508\n","0 26.999999965780887\n","0 26.999999965748188\n","0 26.99999996571541\n","0 26.999999965682555\n","0 26.999999965649618\n","0 26.999999965616603\n","0 26.99999996558351\n","0 26.99999996555033\n","0 26.999999965517077\n","0 26.99999996548374\n","0 26.99999996545032\n","0 26.999999965416826\n","0 26.999999965383243\n","0 26.99999996534958\n","0 26.999999965315837\n","0 26.999999965282008\n","0 26.9999999652481\n","0 26.999999965214105\n","0 26.999999965180024\n","0 26.99999996514586\n","0 26.999999965111616\n","0 26.999999965077283\n","0 26.999999965042868\n","0 26.999999965008367\n","0 26.99999996497378\n","0 26.999999964939107\n","0 26.999999964904344\n","0 26.999999964869502\n","0 26.999999964834565\n","0 26.999999964799542\n","0 26.999999964764434\n","0 26.999999964729234\n","0 26.999999964693945\n","0 26.99999996465857\n","0 26.999999964623104\n","0 26.99999996458755\n","0 26.999999964551904\n","0 26.999999964516167\n","0 26.999999964480338\n","0 26.99999996444442\n","0 26.99999996440841\n","0 26.999999964372307\n","0 26.999999964336112\n","0 26.999999964299825\n","0 26.999999964263445\n","0 26.999999964226966\n","0 26.9999999641904\n","0 26.999999964153737\n","0 26.999999964116977\n","0 26.99999996408012\n","0 26.999999964043177\n","0 26.99999996400613\n","0 26.999999963968985\n","0 26.99999996393175\n","0 26.999999963894414\n","0 26.999999963856975\n","0 26.99999996381944\n","0 26.999999963781814\n","0 26.99999996374408\n","0 26.99999996370625\n","0 26.999999963668323\n","0 26.999999963630295\n","0 26.99999996359216\n","0 26.999999963553933\n","0 26.9999999635156\n","0 26.99999996347716\n","0 26.999999963438622\n","0 26.99999996339998\n","0 26.999999963361237\n","0 26.999999963322384\n","0 26.99999996328343\n","0 26.999999963244374\n","0 26.99999996320521\n","0 26.99999996316594\n","0 26.999999963126566\n","0 26.99999996308708\n","0 26.999999963047493\n","0 26.999999963007795\n","0 26.999999962967987\n","0 26.99999996292808\n","0 26.99999996288805\n","0 26.999999962847916\n","0 26.99999996280767\n","0 26.99999996276732\n","0 26.999999962726854\n","0 26.999999962686278\n","0 26.99999996264559\n","0 26.99999996260479\n","0 26.999999962563873\n","0 26.99999996252284\n","0 26.999999962481702\n","0 26.99999996244044\n","0 26.999999962399066\n","0 26.999999962357577\n","0 26.99999996231597\n","0 26.99999996227425\n","0 26.999999962232415\n","0 26.999999962190458\n","0 26.99999996214838\n","0 26.99999996210618\n","0 26.999999962063868\n","0 26.999999962021434\n"]}]},{"cell_type":"code","source":["# Training loop\n","while loss.item() > 10:\n","    for i in range(0,1000):\n","      # Forward pass\n","      in_data = train_images_flattened[k:10+k]\n","      in_labels = train_labels[k:10+k]\n","      #print(len(train_images_flattened))\n","      xs =  [torch.tensor(data, dtype=torch.double, device=device) for data in in_data]\n","      ypred = [brein(im) for im in xs]\n","      ys = []\n","      for npred in in_labels:\n","        item_pred = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.double, device=device)\n","        item_pred[npred] = 1\n","        ys.append(item_pred)\n","\n","      #loss = 0\n","      loss = torch.tensor(0, dtype=torch.double, device=device)\n","      for val, pred in zip(ys, ypred):\n","        loss += sum((yout - ygt)**2 for ygt, yout in zip(val, pred))\n","\n","      #loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n","      #print(loss)\n","\n","\n","      # Backward pass\n","      for p in brein.parameters():\n","          if p.grad is not None:\n","              p.grad.zero_()\n","      loss.backward()\n","\n","      # Update\n","      with torch.no_grad():\n","          for p in brein.parameters():\n","              if p.grad is not None:\n","                  p -= 0.01 * p.grad\n","\n","      print(k, loss.item())\n","    k+= 1\n"],"metadata":{"id":"qLvVGvVO-5Zq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#  Testing the Trained Network\n","\"\"\"\n","xs = [[0.5, -1.5], [1.0, 1.0], [-0.5, -0.5]]\n","ys = [1.0, -1.0, 0.5]\n","\"\"\"\n","\n","\n","n(xs[1])"],"metadata":{"id":"jQ7k2wU8XWTY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(torch.cuda.is_available())\n","print(torch.cuda.get_device_name(0))"],"metadata":{"id":"Sr7IdjI17N_U"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}